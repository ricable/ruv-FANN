//! Training binary for the handover prediction model
//!
//! This binary trains a neural network model using historical UE metrics
//! and handover events, targeting >90% accuracy.

use clap::{Arg, Command};
use opt_mob_01::{
    backtesting::{BacktestingFramework, BacktestConfig},
    data::{HandoverDataset, UeMetrics, HandoverEvent},
    model::{HandoverModel, ModelConfig, TrainingConfig},
    utils::{DataGenerator, PerformanceMonitor, ValidationUtils},
    MINIMUM_ACCURACY_TARGET,
};
use std::path::Path;
use tracing::{error, info, warn};

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    // Initialize tracing
    tracing_subscriber::fmt::init();
    
    let matches = Command::new("train-handover-model")
        .version("1.0.0")
        .author("HandoverPredictorAgent <agent@ruv-fann.ai>")
        .about("Train the OPT-MOB-01 Handover Prediction Model")
        .arg(
            Arg::new("train-data")
                .long("train-data")
                .value_name("FILE")
                .help("Training metrics CSV file")
                .required(false)
        )
        .arg(
            Arg::new("train-events")
                .long("train-events")
                .value_name("FILE")
                .help("Training handover events CSV file")
                .required(false)
        )
        .arg(
            Arg::new("test-data")
                .long("test-data")
                .value_name("FILE")
                .help("Test metrics CSV file (optional)")
        )
        .arg(
            Arg::new("test-events")
                .long("test-events")
                .value_name("FILE")
                .help("Test handover events CSV file (optional)")
        )
        .arg(
            Arg::new("output")
                .short('o')
                .long("output")
                .value_name("FILE")
                .help("Output model file")
                .default_value("models/handover_v1.bin")
        )
        .arg(
            Arg::new("synthetic")
                .long("synthetic")
                .help("Generate and use synthetic training data")
                .action(clap::ArgAction::SetTrue)
        )
        .arg(
            Arg::new("epochs")
                .long("epochs")
                .value_name("NUMBER")
                .help("Maximum training epochs")
                .default_value("1000")
        )
        .arg(
            Arg::new("learning-rate")
                .long("learning-rate")
                .value_name("RATE")
                .help("Learning rate")
                .default_value("0.001")
        )
        .arg(
            Arg::new("batch-size")
                .long("batch-size")
                .value_name("SIZE")
                .help("Training batch size")
                .default_value("32")
        )
        .arg(
            Arg::new("hidden-layers")
                .long("hidden-layers")
                .value_name("LAYERS")
                .help("Hidden layer sizes (comma-separated)")
                .default_value("128,64,32")
        )
        .arg(
            Arg::new("validation-split")
                .long("validation-split")
                .value_name("RATIO")
                .help("Validation split ratio")
                .default_value("0.2")
        )
        .arg(
            Arg::new("cross-validation")
                .long("cross-validation")
                .help("Enable cross-validation")
                .action(clap::ArgAction::SetTrue)
        )
        .arg(
            Arg::new("backtest")
                .long("backtest")
                .help("Run comprehensive backtesting")
                .action(clap::ArgAction::SetTrue)
        )
        .arg(
            Arg::new("config")
                .short('c')
                .long("config")
                .value_name("FILE")
                .help("Training configuration file")
        )
        .get_matches();
    
    let mut monitor = PerformanceMonitor::new();
    
    // Parse command line arguments
    let output_path = matches.get_one::<String>("output").unwrap();
    let epochs: u32 = matches.get_one::<String>("epochs").unwrap().parse()?;
    let learning_rate: f64 = matches.get_one::<String>("learning-rate").unwrap().parse()?;
    let batch_size: usize = matches.get_one::<String>("batch-size").unwrap().parse()?;
    let validation_split: f64 = matches.get_one::<String>("validation-split").unwrap().parse()?;
    let use_synthetic = matches.get_flag("synthetic");
    let enable_cv = matches.get_flag("cross-validation");
    let enable_backtest = matches.get_flag("backtest");
    
    // Parse hidden layers
    let hidden_layers: Vec<usize> = matches.get_one::<String>("hidden-layers")
        .unwrap()
        .split(',')
        .map(|s| s.trim().parse::<usize>())
        .collect::<Result<Vec<_>, _>>()?;
    
    info!("üß† Starting OPT-MOB-01 Handover Prediction Model Training");
    info!("Configuration:");
    info!("  - Max Epochs: {}", epochs);
    info!("  - Learning Rate: {}", learning_rate);
    info!("  - Batch Size: {}", batch_size);
    info!("  - Hidden Layers: {:?}", hidden_layers);
    info!("  - Validation Split: {:.1}%", validation_split * 100.0);
    info!("  - Cross Validation: {}", if enable_cv { "Yes" } else { "No" });
    info!("  - Comprehensive Backtesting: {}", if enable_backtest { "Yes" } else { "No" });
    info!("  - Target Accuracy: >={:.1}%", MINIMUM_ACCURACY_TARGET * 100.0);
    
    // Create output directory
    if let Some(parent) = Path::new(output_path).parent() {
        std::fs::create_dir_all(parent)?;
    }
    
    // Load or generate dataset
    let dataset = if use_synthetic {
        info!("üìä Generating synthetic training dataset...");
        generate_synthetic_dataset().await?
    } else {
        info!("üìä Loading training dataset from files...");
        load_dataset_from_files(&matches).await?
    };
    
    monitor.checkpoint("Data Loading");
    
    // Validate dataset
    info!("üîç Validating dataset quality...");
    let validation_report = ValidationUtils::validate_dataset(&dataset)?;
    
    if !validation_report.is_valid() {
        error!("‚ùå Dataset validation failed:");
        for error in &validation_report.errors {
            error!("  - {}", error);
        }
        std::process::exit(1);
    }
    
    if !validation_report.warnings.is_empty() {
        warn!("‚ö†Ô∏è  Dataset validation warnings:");
        for warning in &validation_report.warnings {
            warn!("  - {}", warning);
        }
    }
    
    info!("‚úÖ Dataset validation successful");
    info!("{}", validation_report.summary());
    
    monitor.checkpoint("Data Validation");
    
    // Create model configuration
    let mut model_config = ModelConfig {
        input_size: 57, // From feature extraction
        hidden_layers,
        output_size: 1,
        learning_rate,
        max_epochs: epochs,
        validation_split,
        batch_size: Some(batch_size),
        ..Default::default()
    };
    
    // Load configuration from file if provided
    if let Some(config_path) = matches.get_one::<String>("config") {
        if Path::new(config_path).exists() {
            info!("üìã Loading training configuration from: {}", config_path);
            // In a full implementation, we'd load the config from file
            // For now, we'll use the command line parameters
        }
    }
    
    let training_config = TrainingConfig {
        model_config: model_config.clone(),
        early_stopping: true,
        early_stopping_patience: 50,
        cross_validation_folds: if enable_cv { Some(5) } else { None },
        ..Default::default()
    };
    
    // Run comprehensive backtesting if requested
    if enable_backtest {
        info!("üî¨ Running comprehensive backtesting...");
        run_comprehensive_backtest(&dataset, &training_config).await?;
        monitor.checkpoint("Comprehensive Backtesting");
    } else {
        // Standard training
        info!("üéØ Starting model training...");
        let model = train_model(&dataset, &training_config).await?;
        monitor.checkpoint("Model Training");
        
        // Save model
        info!("üíæ Saving trained model to: {}", output_path);
        model.save(output_path)?;
        info!("‚úÖ Model saved successfully");
        
        // Display model information
        let model_info = model.get_model_info();
        info!("üìä Final Model Statistics:");
        info!("  - Model ID: {}", model_info.model_id);
        info!("  - Training Accuracy: {:.4} ({:.1}%)", model_info.training_accuracy, model_info.training_accuracy * 100.0);
        info!("  - Validation Accuracy: {:.4} ({:.1}%)", model_info.validation_accuracy, model_info.validation_accuracy * 100.0);
        info!("  - Total Features: {}", model_info.total_features);
        
        // Check if model meets requirements
        if model_info.validation_accuracy >= MINIMUM_ACCURACY_TARGET {
            info!("üéâ SUCCESS: Model meets minimum accuracy requirement!");
            info!("‚úÖ Validation accuracy {:.1}% >= target {:.1}%", 
                 model_info.validation_accuracy * 100.0,
                 MINIMUM_ACCURACY_TARGET * 100.0);
        } else {
            warn!("‚ö†Ô∏è  WARNING: Model accuracy below target!");
            warn!("‚ùå Validation accuracy {:.1}% < target {:.1}%", 
                 model_info.validation_accuracy * 100.0,
                 MINIMUM_ACCURACY_TARGET * 100.0);
            warn!("üí° Consider:");
            warn!("  - Increasing training epochs");
            warn!("  - Adjusting learning rate");
            warn!("  - Adding more training data");
            warn!("  - Tuning network architecture");
        }
    }
    
    // Performance report
    info!("‚è±Ô∏è  Training Performance Report:");
    info!("{}", monitor.report());
    
    info!("üéØ Training completed successfully!");
    
    Ok(())
}

/// Generate synthetic dataset for training
async fn generate_synthetic_dataset() -> Result<HandoverDataset, Box<dyn std::error::Error>> {
    let mut generator = DataGenerator::new();
    
    info!("Generating comprehensive synthetic dataset...");
    info!("  - 100 UEs over 48 hours");
    info!("  - 1 sample per minute");
    info!("  - 5% handover rate");
    
    let dataset = generator.generate_dataset(
        100,  // 100 UEs
        48.0, // 48 hours of data
        60,   // 1 sample per minute
        0.05, // 5% handover rate
    );
    
    info!("Synthetic dataset generated:");
    info!("  - Total samples: {}", dataset.ue_metrics.len());
    info!("  - Handover events: {}", dataset.handover_events.len());
    info!("  - Unique UEs: {}", dataset.metadata.unique_ues);
    info!("  - Unique cells: {}", dataset.metadata.unique_cells);
    
    Ok(dataset)
}

/// Load dataset from CSV files
async fn load_dataset_from_files(matches: &clap::ArgMatches) -> Result<HandoverDataset, Box<dyn std::error::Error>> {
    // For this implementation, we'll generate synthetic data if no files are provided
    // In a real implementation, this would parse CSV files
    
    if matches.get_one::<String>("train-data").is_none() {
        warn!("No training data files specified, generating synthetic data instead");
        return generate_synthetic_dataset().await;
    }
    
    let train_data_path = matches.get_one::<String>("train-data").unwrap();
    let train_events_path = matches.get_one::<String>("train-events").unwrap();
    
    if !Path::new(train_data_path).exists() {
        error!("Training data file not found: {}", train_data_path);
        error!("üí° Use --synthetic flag to generate synthetic data");
        std::process::exit(1);
    }
    
    if !Path::new(train_events_path).exists() {
        error!("Training events file not found: {}", train_events_path);
        std::process::exit(1);
    }
    
    info!("üìÅ Loading training data from:");
    info!("  - Metrics: {}", train_data_path);
    info!("  - Events: {}", train_events_path);
    
    // For now, generate synthetic data as CSV parsing is not implemented
    warn!("CSV parsing not yet implemented, generating synthetic data");
    generate_synthetic_dataset().await
}

/// Train the handover prediction model
async fn train_model(
    dataset: &HandoverDataset,
    training_config: &TrainingConfig,
) -> Result<HandoverModel, Box<dyn std::error::Error>> {
    use opt_mob_01::features::FeatureExtractor;
    use std::collections::HashMap;
    
    info!("üîß Preparing training data...");
    
    // Extract features and labels from dataset
    let mut feature_extractor = FeatureExtractor::new(10);
    let mut all_features = Vec::new();
    let mut all_labels = Vec::new();
    
    // Group metrics by UE
    let mut ue_metrics = HashMap::new();
    for metrics in &dataset.ue_metrics {
        ue_metrics.entry(metrics.ue_id.clone())
            .or_insert_with(Vec::new)
            .push(metrics.clone());
    }
    
    // Create handover labels map
    let mut handover_map = HashMap::new();
    for event in &dataset.handover_events {
        handover_map.insert(
            (event.ue_id.clone(), event.handover_timestamp),
            true
        );
    }
    
    // Extract features
    info!("üîç Extracting features from {} UE time series...", ue_metrics.len());
    
    for (ue_id, metrics_list) in ue_metrics {
        // Sort by timestamp
        let mut sorted_metrics = metrics_list;
        sorted_metrics.sort_by_key(|m| m.timestamp);
        
        feature_extractor.reset();
        
        for metrics in sorted_metrics {
            feature_extractor.add_metrics(metrics.clone());
            
            if feature_extractor.is_ready() {
                if let Ok(feature_vec) = feature_extractor.extract_features() {
                    all_features.push(feature_vec);
                    
                    // Check if handover occurred within prediction horizon
                    let label = check_handover_within_horizon(&ue_id, &metrics, &handover_map);
                    all_labels.push(label);
                }
            }
        }
    }
    
    info!("üìä Feature extraction completed:");
    info!("  - Total feature vectors: {}", all_features.len());
    info!("  - Positive samples (handover): {}", all_labels.iter().filter(|&&x| x == 1.0).count());
    info!("  - Negative samples (no handover): {}", all_labels.iter().filter(|&&x| x == 0.0).count());
    info!("  - Class balance: {:.1}%", all_labels.iter().filter(|&&x| x == 1.0).count() as f64 / all_labels.len() as f64 * 100.0);
    
    // Split into train/validation
    let split_idx = (all_features.len() as f64 * (1.0 - training_config.model_config.validation_split)) as usize;
    let (train_features, val_features) = all_features.split_at(split_idx);
    let (train_labels, val_labels) = all_labels.split_at(split_idx);
    
    info!("üìà Dataset split:");
    info!("  - Training samples: {}", train_features.len());
    info!("  - Validation samples: {}", val_features.len());
    
    // Create and train model
    info!("üß† Creating neural network model...");
    let mut model = HandoverModel::new(training_config.model_config.clone())?;
    
    info!("üéØ Starting training process...");
    let training_history = model.train(
        train_features,
        train_labels,
        Some(val_features),
        Some(val_labels),
        training_config,
    )?;
    
    info!("‚úÖ Training completed:");
    info!("  - Epochs completed: {}", training_history.epochs_completed);
    info!("  - Best epoch: {}", training_history.best_epoch);
    info!("  - Best validation accuracy: {:.4} ({:.1}%)", 
         training_history.best_validation_accuracy,
         training_history.best_validation_accuracy * 100.0);
    info!("  - Training time: {:.2}s", training_history.total_training_time_ms as f64 / 1000.0);
    
    Ok(model)
}

/// Run comprehensive backtesting
async fn run_comprehensive_backtest(
    dataset: &HandoverDataset,
    training_config: &TrainingConfig,
) -> Result<(), Box<dyn std::error::Error>> {
    info!("üî¨ Starting comprehensive backtesting framework...");
    
    let backtest_config = BacktestConfig {
        cross_validation_folds: 5,
        enable_feature_importance: true,
        enable_temporal_analysis: true,
        ..Default::default()
    };
    
    let framework = BacktestingFramework::new(backtest_config);
    
    info!("Running backtesting with:");
    info!("  - 5-fold cross-validation");
    info!("  - Feature importance analysis");
    info!("  - Temporal pattern analysis");
    info!("  - Comprehensive error analysis");
    
    let results = framework.run_backtest(dataset, training_config).await?;
    
    // Display results
    info!("üìä Backtesting Results:");
    info!("Overall Performance:");
    info!("  - Accuracy: {:.4} ({:.1}%)", results.overall_metrics.accuracy, results.overall_metrics.accuracy * 100.0);
    info!("  - Precision: {:.4}", results.overall_metrics.precision);
    info!("  - Recall: {:.4}", results.overall_metrics.recall);
    info!("  - F1-Score: {:.4}", results.overall_metrics.f1_score);
    info!("  - AUC-ROC: {:.4}", results.overall_metrics.auc_roc);
    info!("  - Matthews Correlation: {:.4}", results.overall_metrics.matthews_correlation);
    
    // Cross-validation results
    if !results.cross_validation_results.is_empty() {
        info!("Cross-Validation Results:");
        let cv_accuracies: Vec<f64> = results.cross_validation_results.iter()
            .map(|fold| fold.metrics.accuracy)
            .collect();
        let mean_accuracy = cv_accuracies.iter().sum::<f64>() / cv_accuracies.len() as f64;
        let std_accuracy = {
            let variance = cv_accuracies.iter()
                .map(|acc| (acc - mean_accuracy).powi(2))
                .sum::<f64>() / cv_accuracies.len() as f64;
            variance.sqrt()
        };
        
        info!("  - Mean Accuracy: {:.4} ¬± {:.4}", mean_accuracy, std_accuracy);
        for (i, fold) in results.cross_validation_results.iter().enumerate() {
            info!("  - Fold {}: {:.4} ({:.1}%)", i + 1, fold.metrics.accuracy, fold.metrics.accuracy * 100.0);
        }
    }
    
    // Feature importance
    if !results.feature_importance.is_empty() {
        info!("Top 10 Most Important Features:");
        let mut importance_vec: Vec<_> = results.feature_importance.iter().collect();
        importance_vec.sort_by(|a, b| b.1.partial_cmp(a.1).unwrap());
        
        for (i, (feature, importance)) in importance_vec.iter().take(10).enumerate() {
            info!("  {}. {}: {:.4}", i + 1, feature, importance);
        }
    }
    
    // Performance benchmarks
    info!("Performance Benchmarks:");
    info!("  - Average prediction time: {:.2}ms", results.performance_benchmarks.average_prediction_time_ms);
    info!("  - Throughput: {:.0} predictions/sec", results.performance_benchmarks.throughput_predictions_per_second);
    info!("  - Model size: {:.1}MB", results.performance_benchmarks.model_size_mb);
    
    // Dataset statistics
    info!("Dataset Statistics:");
    info!("  - Total samples: {}", results.dataset_statistics.total_samples);
    info!("  - Handover rate: {:.2}%", results.dataset_statistics.handover_rate * 100.0);
    info!("  - Unique UEs: {}", results.dataset_statistics.unique_ues);
    info!("  - Time span: {:.1} hours", results.dataset_statistics.time_span_hours);
    
    // Error analysis
    info!("Error Analysis:");
    info!("  - False positive rate: {:.2}%", results.recommendation_accuracy.false_alarm_rate * 100.0);
    info!("  - Missed detection rate: {:.2}%", results.recommendation_accuracy.missed_detection_rate * 100.0);
    info!("  - Target cell accuracy: {:.1}%", results.recommendation_accuracy.target_cell_accuracy * 100.0);
    
    // Final assessment
    if results.overall_metrics.accuracy >= MINIMUM_ACCURACY_TARGET {
        info!("üéâ SUCCESS: Model meets minimum accuracy requirement!");
        info!("‚úÖ Overall accuracy {:.1}% >= target {:.1}%", 
             results.overall_metrics.accuracy * 100.0,
             MINIMUM_ACCURACY_TARGET * 100.0);
        
        info!("üöÄ Model is ready for production deployment!");
    } else {
        warn!("‚ö†Ô∏è  WARNING: Model accuracy below target!");
        warn!("‚ùå Overall accuracy {:.1}% < target {:.1}%", 
             results.overall_metrics.accuracy * 100.0,
             MINIMUM_ACCURACY_TARGET * 100.0);
        
        info!("üí° Recommendations for improvement:");
        info!("  - Collect more diverse training data");
        info!("  - Feature engineering improvements");
        info!("  - Hyperparameter tuning");
        info!("  - Ensemble methods");
        info!("  - Address systematic errors identified");
    }
    
    Ok(())
}

/// Check if handover occurred within prediction horizon
fn check_handover_within_horizon(
    ue_id: &str,
    metrics: &UeMetrics,
    handover_map: &HashMap<(String, chrono::DateTime<chrono::Utc>), bool>,
) -> f64 {
    let horizon = chrono::Duration::seconds(30); // 30-second prediction horizon
    let end_time = metrics.timestamp + horizon;
    
    // Check if any handover occurred for this UE within the time window
    for ((id, timestamp), _) in handover_map {
        if id == ue_id && *timestamp >= metrics.timestamp && *timestamp <= end_time {
            return 1.0; // Handover will occur
        }
    }
    
    0.0 // No handover
}

#[cfg(test)]
mod tests {
    use super::*;
    
    #[tokio::test]
    async fn test_synthetic_dataset_generation() {
        let dataset = generate_synthetic_dataset().await.unwrap();
        assert!(!dataset.ue_metrics.is_empty());
        assert!(!dataset.handover_events.is_empty());
    }
    
    #[test]
    fn test_handover_horizon_check() {
        use chrono::Utc;
        use std::collections::HashMap;
        
        let ue_id = "UE_001";
        let now = Utc::now();
        let metrics = UeMetrics::new(ue_id, "Cell_001").with_timestamp(now);
        
        let mut handover_map = HashMap::new();
        handover_map.insert((ue_id.to_string(), now + chrono::Duration::seconds(15)), true);
        
        let result = check_handover_within_horizon(ue_id, &metrics, &handover_map);
        assert_eq!(result, 1.0); // Should predict handover
        
        // Test case where handover is outside horizon
        handover_map.clear();
        handover_map.insert((ue_id.to_string(), now + chrono::Duration::seconds(60)), true);
        
        let result = check_handover_within_horizon(ue_id, &metrics, &handover_map);
        assert_eq!(result, 0.0); // Should not predict handover
    }
}